{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from matplotlib.pyplot import text\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from numpy import linalg\n",
    "import statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(labeled_df):\n",
    "    data_copy_df = labeled_df.copy()\n",
    "    data_no_duplicates = data_copy_df.drop_duplicates(subset = ['text'])\n",
    "    return data_no_duplicates\n",
    "\n",
    "file_path_l = []\n",
    "\n",
    "for root, dirs, files in os.walk('InternClustersTextAlexisNoSub'):\n",
    "    for filename in files:\n",
    "        file_path_l.append(os.path.join(root, filename))\n",
    "\n",
    "text_l = []\n",
    "for file_path in file_path_l:\n",
    "    filey = open(file_path,encoding=\"mbcs\")\n",
    "    text_l.append(filey.read())\n",
    "    filey.close()\n",
    "types_l = []\n",
    "for namey in file_path_l:\n",
    "    splitted = namey.split('\\\\')\n",
    "    types_l.append(splitted[1])\n",
    "#print(types_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = api.load('text8')\n",
    "#dataset = api.load(\"wiki-english-20171001\")\n",
    "data = [d for d in dataset]\n",
    "\n",
    "def tagged_document(list_of_list_of_words):\n",
    "   for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "      yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i])\n",
    "data_for_training = list(tagged_document(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(epochs=30)\n",
    "model.build_vocab(data_for_training)\n",
    "model.train(data_for_training, total_examples=model.corpus_count, epochs=model.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(vector1,vector2):\n",
    "    cosV12 = np.dot(vector1, vector2) / (linalg.norm(vector1) * linalg.norm(vector2))\n",
    "    return cosV12\n",
    "\n",
    "dataset = text_l\n",
    "List_of_List_of_words = []\n",
    "for x in range(len(dataset)):\n",
    "   List_of_List_of_words.append(dataset[x].split())\n",
    "#print(model.infer_vector(List_of_List_of_words[0]))\n",
    "vector1 = model.infer_vector(List_of_List_of_words[0])\n",
    "vector2 = model.infer_vector(List_of_List_of_words[9])\n",
    "vector3 = model.infer_vector(List_of_List_of_words[-1])\n",
    "print(\"Vectors in the same category:\", cosine(vector1,vector2))\n",
    "print(\"Vectors in different categories:\", cosine(vector1,vector3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for i in range(len(List_of_List_of_words)):\n",
    "    vectors.append(model.infer_vector(List_of_List_of_words[i]))\n",
    "print(len(vectors))\n",
    "score = silhouette_score(vectors, types_l)\n",
    "scoreC = silhouette_score(vectors, types_l, metric = \"cosine\")\n",
    "scoreM = silhouette_score(vectors, types_l, metric = \"manhattan\")\n",
    "print(\"Full dimensions:\", score)\n",
    "print(\"Full dimensions:\", scoreC)\n",
    "print(\"Full dimensinos:\", scoreM)\n",
    "\n",
    "samples = silhouette_samples(vectors, types_l, metric = \"cosine\")\n",
    "\n",
    "types = list(set(types_l))\n",
    "\n",
    "dict = {}\n",
    "\n",
    "for label in types:\n",
    "    dict[label] = []\n",
    "\n",
    "for i in range(len(types_l)):\n",
    "    dict[types_l[i]].append(samples[i])\n",
    "\n",
    "#print(dict)\n",
    "\n",
    "for key, value in dict.items():\n",
    "    print(key, \": \", statistics.mean(value))\n",
    "\n",
    "'''\n",
    "pca2 = PCA(2)\n",
    "vectors2 = pca2.fit_transform(vectors)\n",
    "score2 = silhouette_score(vectors2, types_l)\n",
    "score2C = silhouette_score(vectors2, types_l, metric = \"cosine\")\n",
    "score2M = silhouette_score(vectors2, types_l, metric = \"manhattan\")\n",
    "print(\"2 dimensions:\", score2)\n",
    "print(\"2 dimensions:\", score2C)\n",
    "print(\"2 dimensinos:\", score2M)\n",
    "\n",
    "pca10 = PCA(10)\n",
    "vectors10 = pca10.fit_transform(vectors)\n",
    "score10 = silhouette_score(vectors10, types_l)\n",
    "score10C = silhouette_score(vectors10, types_l, metric = \"cosine\")\n",
    "score10M = silhouette_score(vectors10, types_l, metric = \"manhattan\")\n",
    "print(\"10 dimensions:\", score10)\n",
    "print(\"10 dimensions:\", score10C)\n",
    "print(\"10 dimensinos:\", score10M)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docGroups = []\n",
    "for x in range(len(List_of_List_of_words)):\n",
    "    vector1 = model.infer_vector(List_of_List_of_words[x])\n",
    "    tempList = []\n",
    "    for y in range(len(List_of_List_of_words)):\n",
    "        vector2 = model.infer_vector(List_of_List_of_words[y])\n",
    "        if(cosine(vector1, vector2) >.75):\n",
    "            tempList.append(y)\n",
    "    docGroups.append(tempList)\n",
    "\n",
    "for i in docGroups:\n",
    "    print(i)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4bec7b648d61350689a0ccb93b53155b5d49d036bbaf30ce84901e3a87cea97"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
